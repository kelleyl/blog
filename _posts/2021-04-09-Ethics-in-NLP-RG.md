---
layout: post
title:  Ethics in NLP Reading Group Discussion
date:   2021-04-09
description: The Brandeis Ethics in NLP Reading Group meets biweekly to discuss special topics related to ethics in AI. I will be leading the discussion for April 9, 2021. The topic for this week is content moderation.
---
Content moderation, web platforms and social networks making decisions about the content they serve. This process has many methods
    - filtering content (never allowing a post with a particular word)
    - removing content
    - ending discussion on a post (turning off comments)\
    - not showing a post on news feeds/time lines/home pages 
What does automated moderation look like?
Is "the algorithm" inherently a content moderation system?
How can we evaluate an automated moderation system?
Political Consequences? section 230, cesta/fosta
Deplatforming? removal from aws, other web infrastructure

public datasets?
sota approaches

https://podcasts.apple.com/us/podcast/the-radical-ai-podcast/id1505229145?i=1000515134671
https://www.nytimes.com/2021/04/06/podcasts/the-daily/a-vast-web-of-vengeance.html
https://podcasts.apple.com/us/podcast/radiolab/id152249110?i=1000508726239

The discussion was interesting. One new product that was brought up that I had not heard about was Intel Bleep. We discussed potential privacy issues with this type of technology. 
